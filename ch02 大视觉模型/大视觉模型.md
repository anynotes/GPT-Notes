### 4.1 分割一切(segment anything,SAM)


随着大语言模型和transformer在视觉领域应用的发展，出现了大视觉模型，iccv2023 the best paper《segment anything》所提出的分割一切模型就是大视觉模型的代表。分割一切模型的目的是建立一个分割领域的通用模型，包括边缘检测、目标检测、实例分割、文本驱动分割。通过3个部分实现：1）可以prompt输入；2）具有数据标注和零样本泛化能力的分割模型；3）生产大量分割数据集的引擎。


<div align=center>
<img src="./imgs/1.5.21.jpg" width="1200" height="400">
</div>
<div align=center>图21.分割一切 </div>


上图就是SAM的模型结构。主要包括3个部分：1）image encoder，用来获取输入图像的特征；2）prompt encoder，用来对不同的prompt进行编码，也是本文最具亮点的部分；3）mask decoder，用来根据图像的特征和prompt输入相应的mask。


image encoder使用MAE(Masked Autoencoders，掩码自编码器)模型，以原图作为输入，分辨率为1024x1024，输出为256x64x64。MAE 的方法如下图：Mask 掉输入图像的随机的 patches 并重建它们。它基于两个核心理念：研究人员开发了一个非对称编码器 - 解码器架构，其中一个编码器只对可见的 patch 子集进行操作 (即没有被 mask 掉的 token)，另一个简单解码器可以从潜在表征和被 masked 掉的 token 重建原始图像。Decoder 的架构可以是十分轻量化的模型，且具体的架构对模型性能影响很大。


<div align=center>
<img src="./imgs/1.5.22.jpg" width="1200" height="400">
</div>
<div align=center>图22.MAE模型 </div>


prompt encoder针对不同类型的输入是不一样的。点框统一用位置坐标表示，映射到256维。文本使用CLIP的文本编码器。mask使用多层卷积进行编码。具体来说，一个点被表示为该点的位置的位置编码和两个(前景和背景)学习到的嵌入之一的总和，这表明该点是在前景中还是在背景中。框由嵌入对表示： (1)其左上角的位置编码与表示“左上角”的学习嵌入求和，(2)相同的结构，但使用学习嵌入表示“右下角”。


<div align=center>
<img src="./imgs/1.5.23.jpg" width="600" height="300">
</div>
<div align=center>图23.mask decoder </div>


上图为mask decoder，输入为image embedding、output tokens、prompt tokens。output tokens主要是用来控制decoder输出几个mask。输出为多个mask以及对应的置信度。每个解码器层执行4个步骤：(1)对tokens的自注意力，(2)从tokens（作为查询）到图像嵌入，(3)点级MLP更新每个tokens，(4)从图像嵌入（作为查询）到tokens。最后一步将使用提示信息更新图像嵌入。在交叉注意过程中，将图像嵌入作为一组64225个6维向量。每个自我/交叉注意力和MLP都有一个残差连接、层归一化和dropout为0.1。下一个解码器层从上一层中获取更新的tokens和更新的图像嵌入。


下为分割一切的效果图示例。


<div align=center>
<img src="./imgs/1.5.24.jpg" width="1200" height="400">
</div>
<div align=center>图24.分割一切效果图 </div>